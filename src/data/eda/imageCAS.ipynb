{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageCAS dataset EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autorootcwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"data/imageCAS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check data location and Count data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total patient directory count: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking missing files: 100%|██████████| 1000/1000 [00:00<00:00, 21739.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All patient data have img.nii.gz and label.nii.gz files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def check_missing_files(base_path):\n",
    "    directories = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]\n",
    "    total_dirs = len(directories)\n",
    "    \n",
    "    print(f\"\\nTotal patient directory count: {total_dirs}\")\n",
    "\n",
    "    missing_patients = []\n",
    "    \n",
    "    for dir_name in tqdm(directories, desc=\"Checking missing files\"):\n",
    "        dir_path = os.path.join(base_path, dir_name)\n",
    "        img_exists = os.path.exists(os.path.join(dir_path, 'img.nii.gz'))\n",
    "        label_exists = os.path.exists(os.path.join(dir_path, 'label.nii.gz'))\n",
    "        \n",
    "        if not (img_exists and label_exists):\n",
    "            missing_files = []\n",
    "            if not img_exists: missing_files.append('img.nii.gz')\n",
    "            if not label_exists: missing_files.append('label.nii.gz')\n",
    "            missing_patients.append((dir_name, missing_files))\n",
    "    \n",
    "    if missing_patients:\n",
    "        print(\"\\nPatients with missing files:\")\n",
    "        for patient_id, missing_files in missing_patients:\n",
    "            print(f\"Patient {patient_id}: {', '.join(missing_files)} missing\")\n",
    "    else:\n",
    "        print(\"\\nAll patient data have img.nii.gz and label.nii.gz files.\")\n",
    "\n",
    "check_missing_files(base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get nifTi file metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "header info is saved in src/eda/imageCAS_nifti_header_info.txt\n"
     ]
    }
   ],
   "source": [
    "data_number = 1\n",
    "nii = nib.load(\"data/imageCAS/{}/img.nii.gz\".format(data_number))\n",
    "\n",
    "output_dir = \"src/eda/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "output_file = os.path.join(output_dir, \"imageCAS_nifti_header_info.txt\")\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "\n",
    "    f.write(\"=== NIfTI Header Info [{}]===\\n\\n\".format(data_number))\n",
    "    \n",
    "    f.write(str(nii.header))\n",
    "    f.write(\"\\n\\n=== Detailed Header Info ===\\n\\n\")\n",
    "    \n",
    "    for field in nii.header:\n",
    "        f.write(f\"{field}: {nii.header[field]}\\n\")\n",
    "    \n",
    "    f.write(\"\\n=== Additional Info ===\\n\")\n",
    "    f.write(f\"data type: {nii.get_data_dtype()}\\n\")\n",
    "    f.write(f\"image size: {nii.shape}\\n\")\n",
    "    f.write(f\"header size: {nii.header.sizeof_hdr} bytes\\n\")\n",
    "\n",
    "print(f\"header info is saved in {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check shape and voxel size of the image and label match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_match_img_and_label(base_path):\n",
    "    results = []\n",
    "    \n",
    "    for i in tqdm(range(1, 1001)):\n",
    "        folder = str(i)\n",
    "        folder_path = os.path.join(base_path, folder)\n",
    "        \n",
    "        if not os.path.exists(folder_path):\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            img_path = os.path.join(folder_path, 'img.nii.gz')\n",
    "            label_path = os.path.join(folder_path, 'label.nii.gz')\n",
    "            \n",
    "            # image file analysis\n",
    "            if os.path.exists(img_path):\n",
    "                img_nii = nib.load(img_path)\n",
    "                img_shape = img_nii.shape\n",
    "                img_voxel = img_nii.header.get_zooms()\n",
    "            else:\n",
    "                img_shape = None\n",
    "                img_voxel = None\n",
    "                \n",
    "            # label file analysis\n",
    "            if os.path.exists(label_path):\n",
    "                label_nii = nib.load(label_path)\n",
    "                label_shape = label_nii.shape\n",
    "                label_voxel = label_nii.header.get_zooms()\n",
    "            else:\n",
    "                label_shape = None\n",
    "                label_voxel = None\n",
    "                \n",
    "            results.append({\n",
    "                'folder': i,\n",
    "                'img_shape': img_shape,\n",
    "                'img_voxel_size': img_voxel,\n",
    "                'label_shape': label_shape,\n",
    "                'label_voxel_size': label_voxel\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"[Error] Patient id {i}: {str(e)}\")\n",
    "            \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 990.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Analysis Results ===\n",
      "\n",
      "Unique image shape:\n",
      "img_shape\n",
      "(512, 512, 275)    621\n",
      "(512, 512, 206)    126\n",
      "(512, 512, 245)     18\n",
      "(512, 512, 259)     15\n",
      "(512, 512, 241)     15\n",
      "(512, 512, 229)     13\n",
      "(512, 512, 223)     13\n",
      "(512, 512, 249)     12\n",
      "(512, 512, 243)     12\n",
      "(512, 512, 239)     12\n",
      "(512, 512, 247)     11\n",
      "(512, 512, 261)     11\n",
      "(512, 512, 221)     10\n",
      "(512, 512, 253)     10\n",
      "(512, 512, 231)     10\n",
      "(512, 512, 233)      9\n",
      "(512, 512, 225)      9\n",
      "(512, 512, 257)      8\n",
      "(512, 512, 227)      8\n",
      "(512, 512, 237)      7\n",
      "(512, 512, 255)      6\n",
      "(512, 512, 219)      6\n",
      "(512, 512, 263)      6\n",
      "(512, 512, 235)      6\n",
      "(512, 512, 251)      4\n",
      "(512, 512, 217)      4\n",
      "(512, 512, 209)      2\n",
      "(512, 512, 248)      2\n",
      "(512, 512, 267)      2\n",
      "(512, 512, 228)      1\n",
      "(512, 512, 215)      1\n",
      "(512, 512, 187)      1\n",
      "(512, 512, 240)      1\n",
      "(512, 512, 213)      1\n",
      "(512, 512, 236)      1\n",
      "(512, 512, 166)      1\n",
      "(512, 512, 269)      1\n",
      "(512, 512, 277)      1\n",
      "(512, 512, 265)      1\n",
      "(512, 512, 268)      1\n",
      "(512, 512, 200)      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique image voxel size:\n",
      "img_voxel_size\n",
      "(0.31835938, 0.31835938, 0.5)    240\n",
      "(0.34570312, 0.34570312, 0.5)     35\n",
      "(0.36132812, 0.36132812, 0.5)     33\n",
      "(0.34179688, 0.34179688, 0.5)     29\n",
      "(0.34375, 0.34375, 0.5)           29\n",
      "                                ... \n",
      "(0.43554688, 0.43554688, 0.5)      1\n",
      "(0.3125, 0.3125, 0.5)              1\n",
      "(0.29882812, 0.29882812, 0.5)      1\n",
      "(0.4453125, 0.4453125, 0.5)        1\n",
      "(0.453125, 0.453125, 0.5)          1\n",
      "Name: count, Length: 73, dtype: int64\n",
      "\n",
      "All image and label shapes match.\n",
      "\n",
      "All image and label voxel sizes match.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = check_match_img_and_label(base_path)\n",
    "\n",
    "df.to_csv('src/eda/nifti_analysis_results.csv', index=False)\n",
    "\n",
    "print(\"\\n=== Analysis Results ===\")\n",
    "print(\"\\nUnique image shape:\")\n",
    "print(df['img_shape'].value_counts())\n",
    "\n",
    "print(\"\\nUnique image voxel size:\")\n",
    "print(df['img_voxel_size'].value_counts())\n",
    "\n",
    "mismatched_shape = df[df['img_shape'] != df['label_shape']]\n",
    "if not mismatched_shape.empty:\n",
    "    print(\"\\nCases where image and label shape do not match:\")\n",
    "    print(mismatched_shape[['folder', 'img_shape', 'label_shape']])\n",
    "else:\n",
    "    print(\"\\nAll image and label shapes match.\")\n",
    "\n",
    "mismatched_voxel = df[df['img_voxel_size'] != df['label_voxel_size']]\n",
    "if not mismatched_voxel.empty:\n",
    "    print(\"\\nCases where image and label voxel size do not match:\")\n",
    "    print(mismatched_voxel[['folder', 'img_voxel_size', 'label_voxel_size']])\n",
    "else:\n",
    "    print(\"\\nAll image and label voxel sizes match.\")\n",
    "\n",
    "# check missing files\n",
    "missing = df[df['img_shape'].isna() | df['label_shape'].isna()]\n",
    "if not missing.empty:\n",
    "    print(\"\\nFolders with missing files:\")\n",
    "    print(missing['folder'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the voxel size and image shape for each data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_voxel_size_and_image_shape(base_path):\n",
    "    results = []\n",
    "    \n",
    "    for i in tqdm(range(1, 1001)):\n",
    "        folder = str(i)\n",
    "        img_path = os.path.join(base_path, folder, 'img.nii.gz')\n",
    "        \n",
    "        if not os.path.exists(img_path):\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            img_nii = nib.load(img_path)\n",
    "            voxel_size = img_nii.header.get_zooms()\n",
    "            shape = img_nii.shape\n",
    "            \n",
    "            results.append({\n",
    "                'patient_id': i,\n",
    "                'voxel_x': voxel_size[0],\n",
    "                'voxel_y': voxel_size[1],\n",
    "                'voxel_z': voxel_size[2],\n",
    "                'shape_x': shape[0],\n",
    "                'shape_y': shape[1],\n",
    "                'shape_z': shape[2]\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"[Error] Patient id {i}: {str(e)}\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1888.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Voxel Size Statistics ===\n",
      "           voxel_x      voxel_y  voxel_z\n",
      "count  1000.000000  1000.000000   1000.0\n",
      "mean      0.352982     0.352982      0.5\n",
      "std       0.029897     0.029897      0.0\n",
      "min       0.289062     0.289062      0.5\n",
      "25%       0.320312     0.320312      0.5\n",
      "50%       0.349609     0.349609      0.5\n",
      "75%       0.371582     0.371582      0.5\n",
      "max       0.464844     0.464844      0.5\n",
      "\n",
      "=== Unique Voxel Size Combination ===\n",
      "     voxel_x   voxel_y  voxel_z  count\n",
      "6   0.318359  0.318359      0.5    240\n",
      "20  0.345703  0.345703      0.5     35\n",
      "28  0.361328  0.361328      0.5     33\n",
      "18  0.341797  0.341797      0.5     29\n",
      "19  0.343750  0.343750      0.5     29\n",
      "..       ...       ...      ...    ...\n",
      "59  0.421875  0.421875      0.5      1\n",
      "67  0.445312  0.445312      0.5      1\n",
      "66  0.435547  0.435547      0.5      1\n",
      "70  0.453125  0.453125      0.5      1\n",
      "71  0.458984  0.458984      0.5      1\n",
      "\n",
      "[73 rows x 4 columns]\n",
      "\n",
      "=== Check Outliers ===\n",
      "\n",
      "voxel_x outliers:\n",
      "     patient_id   voxel_x\n",
      "16           17  0.429688\n",
      "24           25  0.414062\n",
      "33           34  0.423828\n",
      "75           76  0.464844\n",
      "77           78  0.427734\n",
      "101         102  0.429688\n",
      "126         127  0.423828\n",
      "171         172  0.419922\n",
      "173         174  0.433594\n",
      "176         177  0.447266\n",
      "207         208  0.416016\n",
      "238         239  0.417969\n",
      "257         258  0.458984\n",
      "261         262  0.417969\n",
      "268         269  0.414062\n",
      "297         298  0.464844\n",
      "306         307  0.414062\n",
      "351         352  0.429688\n",
      "415         416  0.289062\n",
      "420         421  0.425781\n",
      "426         427  0.429688\n",
      "450         451  0.425781\n",
      "470         471  0.421875\n",
      "504         505  0.423828\n",
      "539         540  0.433594\n",
      "555         556  0.435547\n",
      "561         562  0.427734\n",
      "606         607  0.417969\n",
      "627         628  0.431641\n",
      "733         734  0.433594\n",
      "734         735  0.416016\n",
      "749         750  0.417969\n",
      "797         798  0.449219\n",
      "807         808  0.414062\n",
      "811         812  0.445312\n",
      "813         814  0.453125\n",
      "817         818  0.447266\n",
      "821         822  0.425781\n",
      "855         856  0.423828\n",
      "872         873  0.414062\n",
      "944         945  0.419922\n",
      "983         984  0.449219\n",
      "984         985  0.417969\n",
      "985         986  0.419922\n",
      "\n",
      "voxel_y outliers:\n",
      "     patient_id   voxel_y\n",
      "16           17  0.429688\n",
      "24           25  0.414062\n",
      "33           34  0.423828\n",
      "75           76  0.464844\n",
      "77           78  0.427734\n",
      "101         102  0.429688\n",
      "126         127  0.423828\n",
      "171         172  0.419922\n",
      "173         174  0.433594\n",
      "176         177  0.447266\n",
      "207         208  0.416016\n",
      "238         239  0.417969\n",
      "257         258  0.458984\n",
      "261         262  0.417969\n",
      "268         269  0.414062\n",
      "297         298  0.464844\n",
      "306         307  0.414062\n",
      "351         352  0.429688\n",
      "415         416  0.289062\n",
      "420         421  0.425781\n",
      "426         427  0.429688\n",
      "450         451  0.425781\n",
      "470         471  0.421875\n",
      "504         505  0.423828\n",
      "539         540  0.433594\n",
      "555         556  0.435547\n",
      "561         562  0.427734\n",
      "606         607  0.417969\n",
      "627         628  0.431641\n",
      "733         734  0.433594\n",
      "734         735  0.416016\n",
      "749         750  0.417969\n",
      "797         798  0.449219\n",
      "807         808  0.414062\n",
      "811         812  0.445312\n",
      "813         814  0.453125\n",
      "817         818  0.447266\n",
      "821         822  0.425781\n",
      "855         856  0.423828\n",
      "872         873  0.414062\n",
      "944         945  0.419922\n",
      "983         984  0.449219\n",
      "984         985  0.417969\n",
      "985         986  0.419922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = analyze_voxel_size_and_image_shape(base_path)\n",
    "\n",
    "print(\"\\n=== Voxel Size Statistics ===\")\n",
    "stats = df[['voxel_x', 'voxel_y', 'voxel_z']].describe()\n",
    "print(stats)\n",
    "\n",
    "# unique voxel size\n",
    "unique_voxels = df.groupby(['voxel_x', 'voxel_y', 'voxel_z']).size().reset_index(name='count')\n",
    "unique_voxels = unique_voxels.sort_values('count', ascending=False)\n",
    "print(\"\\n=== Unique Voxel Size Combination ===\")\n",
    "print(unique_voxels)\n",
    "\n",
    "df.to_csv('src/eda/voxel_size_comparison.csv', index=False)\n",
    "\n",
    "# check outliers (cases more than 2 standard deviations from the mean)\n",
    "print(\"\\n=== Check Outliers ===\")\n",
    "for col in ['voxel_x', 'voxel_y', 'voxel_z']:\n",
    "    mean = df[col].mean()\n",
    "    std = df[col].std()\n",
    "    outliers = df[abs(df[col] - mean) > 2*std]\n",
    "    if not outliers.empty:\n",
    "        print(f\"\\n{col} outliers:\")\n",
    "        print(outliers[['patient_id', col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1924.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Image Shape Statistics ===\n",
      "       shape_x  shape_y      shape_z\n",
      "count   1000.0   1000.0  1000.000000\n",
      "mean     512.0    512.0   257.496000\n",
      "std        0.0      0.0    25.678227\n",
      "min      512.0    512.0   166.000000\n",
      "25%      512.0    512.0   241.000000\n",
      "50%      512.0    512.0   275.000000\n",
      "75%      512.0    512.0   275.000000\n",
      "max      512.0    512.0   277.000000\n",
      "\n",
      "=== Unique Image Shape Combination ===\n",
      "    shape_x  shape_y  shape_z  count\n",
      "39      512      512      275    621\n",
      "3       512      512      206    126\n",
      "24      512      512      245     18\n",
      "22      512      512      241     15\n",
      "32      512      512      259     15\n",
      "14      512      512      229     13\n",
      "10      512      512      223     13\n",
      "20      512      512      239     12\n",
      "23      512      512      243     12\n",
      "27      512      512      249     12\n",
      "25      512      512      247     11\n",
      "33      512      512      261     11\n",
      "29      512      512      253     10\n",
      "15      512      512      231     10\n",
      "9       512      512      221     10\n",
      "11      512      512      225      9\n",
      "16      512      512      233      9\n",
      "31      512      512      257      8\n",
      "12      512      512      227      8\n",
      "19      512      512      237      7\n",
      "17      512      512      235      6\n",
      "34      512      512      263      6\n",
      "30      512      512      255      6\n",
      "8       512      512      219      6\n",
      "7       512      512      217      4\n",
      "28      512      512      251      4\n",
      "4       512      512      209      2\n",
      "36      512      512      267      2\n",
      "26      512      512      248      2\n",
      "0       512      512      166      1\n",
      "6       512      512      215      1\n",
      "2       512      512      200      1\n",
      "1       512      512      187      1\n",
      "5       512      512      213      1\n",
      "21      512      512      240      1\n",
      "13      512      512      228      1\n",
      "18      512      512      236      1\n",
      "35      512      512      265      1\n",
      "37      512      512      268      1\n",
      "38      512      512      269      1\n",
      "40      512      512      277      1\n",
      "\n",
      "=== Check Outliers ===\n",
      "\n",
      "shape_z outliers:\n",
      "     patient_id  shape_z\n",
      "4             5      206\n",
      "6             7      206\n",
      "14           15      206\n",
      "17           18      206\n",
      "28           29      206\n",
      "..          ...      ...\n",
      "981         982      206\n",
      "990         991      206\n",
      "995         996      206\n",
      "996         997      206\n",
      "998         999      206\n",
      "\n",
      "[129 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = analyze_voxel_size_and_image_shape(base_path)\n",
    "\n",
    "print(\"\\n=== Image Shape Statistics ===\")\n",
    "stats = df[['shape_x', 'shape_y', 'shape_z']].describe()\n",
    "print(stats)\n",
    "\n",
    "#unique image shape\n",
    "unique_shapes = df.groupby(['shape_x', 'shape_y', 'shape_z']).size().reset_index(name='count')\n",
    "unique_shapes = unique_shapes.sort_values('count', ascending=False)\n",
    "print(\"\\n=== Unique Image Shape Combination ===\")\n",
    "print(unique_shapes)\n",
    "\n",
    "df.to_csv('src/eda/image_shape_comparison.csv', index=False)\n",
    "\n",
    "# check outliers (cases more than 2 standard deviations from the mean)\n",
    "print(\"\\n=== Check Outliers ===\")\n",
    "for col in ['shape_x', 'shape_y', 'shape_z']:\n",
    "    mean = df[col].mean()\n",
    "    std = df[col].std()\n",
    "    outliers = df[abs(df[col] - mean) > 2*std]\n",
    "    if not outliers.empty:\n",
    "        print(f\"\\n{col} outliers:\")\n",
    "        print(outliers[['patient_id', col]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from tqdm import tqdm\n",
    "from monai.transforms import Resize\n",
    "import multiprocessing as mp\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autorootcwd\n",
    "\n",
    "base_path = \"data/imageCAS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Adjust voxel size and image shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_imageCAS(base_path, output_base=\"D:/imageCAS_preprocessed\", target_spacing=(0.35, 0.35, 0.5), target_xy_size=512, check_interval=100):\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "    \n",
    "    directories = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]\n",
    "    total_dirs = len(directories)\n",
    "    \n",
    "    print(f\"\\nTotal patient directory count: {total_dirs}\")\n",
    "    print(f\"Target voxel spacing: {target_spacing}\")\n",
    "    print(f\"Target x,y size: {target_xy_size}\")\n",
    "    print(f\"Output directory: {output_base}\")\n",
    "    \n",
    "    errors = []\n",
    "    skipped = []\n",
    "    processed = []\n",
    "    \n",
    "    def print_interim_results(current_count):\n",
    "        print(f\"\\n=== Interim Results (Processed directories: {current_count}/{total_dirs}) ===\")\n",
    "        print(f\"Processed: {len(processed)} files\")\n",
    "        print(f\"Skipped: {len(skipped)} files\")\n",
    "        print(f\"Errors: {len(errors)} files\")\n",
    "        if errors:\n",
    "            print(\"\\nRecent errors:\")\n",
    "            for error in errors[-5:]:\n",
    "                print(error)\n",
    "        print(\"=\"*50)\n",
    "\n",
    "    def resample_image(image, current_spacing, target_spacing, affine, is_label=False):\n",
    "        try:\n",
    "            image = image.astype(np.float32)\n",
    "            scale_factors = np.array(current_spacing) / np.array(target_spacing)\n",
    "            \n",
    "            order = 0 if is_label else 1\n",
    "            resampled_image = ndimage.zoom(image, scale_factors, order=order)\n",
    "            \n",
    "            scaling_matrix = np.diag(1 / scale_factors)\n",
    "            new_affine = affine.copy()\n",
    "            new_affine[:3, :3] = affine[:3, :3] @ scaling_matrix[:3, :3]\n",
    "            \n",
    "            return resampled_image, new_affine\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"[Error] Resampling failed: {str(e)}\")\n",
    "\n",
    "    for idx, dir_name in enumerate(tqdm(directories, desc=\"Data preprocessing\")):\n",
    "            input_dir_path = os.path.join(base_path, dir_name)\n",
    "            output_dir_path = os.path.join(output_base, dir_name)\n",
    "            os.makedirs(output_dir_path, exist_ok=True)\n",
    "            \n",
    "            for file_name in ['img.nii.gz', 'label.nii.gz']:\n",
    "                input_file_path = os.path.join(input_dir_path, file_name)\n",
    "                output_file_path = os.path.join(output_dir_path, file_name)\n",
    "                is_label = file_name == 'label.nii.gz'\n",
    "\n",
    "                if not os.path.exists(input_file_path):\n",
    "                    errors.append(f\"Patient {dir_name}: {file_name} file missing\")\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    nii = nib.load(input_file_path)\n",
    "                    current_spacing = nii.header.get_zooms()\n",
    "                    current_shape = nii.shape\n",
    "                    \n",
    "                    def is_close_enough(current, target, rtol=1e-5):\n",
    "                        return np.allclose(current, target, rtol=rtol)\n",
    "\n",
    "                    needs_processing = (\n",
    "                        not is_close_enough(current_spacing, target_spacing) or \n",
    "                        current_shape[0] != target_xy_size or \n",
    "                        current_shape[1] != target_xy_size\n",
    "                    )\n",
    "\n",
    "                    if not needs_processing:\n",
    "                        skipped.append(f\"{dir_name}/{file_name}\")\n",
    "                        continue\n",
    "\n",
    "                    image_data = nii.get_fdata(dtype=np.float32)\n",
    "                    \n",
    "                    resampled_image, new_affine = resample_image(\n",
    "                        image_data, current_spacing, target_spacing, nii.affine, is_label\n",
    "                    )\n",
    "\n",
    "                    resize_mode = 'nearest' if is_label else 'bilinear'\n",
    "                    resize_transform = Resize(\n",
    "                        spatial_size=(target_xy_size, target_xy_size, resampled_image.shape[2]),\n",
    "                        mode=resize_mode\n",
    "                    )\n",
    "                    resized_image = resize_transform(resampled_image[None])[0]\n",
    "                    resized_image = resized_image.numpy()\n",
    "\n",
    "                    if is_label:\n",
    "                        resized_image = np.round(resized_image).astype(np.int32)\n",
    "\n",
    "                    new_nii = nib.Nifti1Image(resized_image, affine=new_affine)\n",
    "                    new_nii.header.set_zooms(target_spacing)\n",
    "                    nib.save(new_nii, output_file_path)\n",
    "\n",
    "                    processed.append(f\"{dir_name}/{file_name}\")\n",
    "\n",
    "                    del nii, image_data, resampled_image, resized_image, new_nii\n",
    "                    gc.collect()\n",
    "\n",
    "                except Exception as e:\n",
    "                    errors.append(f\"Patient {dir_name}, {file_name} processing error: {str(e)}\")\n",
    "                    gc.collect()\n",
    "\n",
    "            if (idx + 1) % check_interval == 0:\n",
    "                print_interim_results(idx + 1)\n",
    "\n",
    "    print(\"\\n=== Final Results ===\")\n",
    "    print(f\"Processed file count: {len(processed)}\")\n",
    "    print(f\"Skipped file count: {len(skipped)}\")\n",
    "    print(f\"Error count: {len(errors)}\")\n",
    "    if errors:\n",
    "        print(\"Error files: \", errors)\n",
    "    \n",
    "    if errors:\n",
    "        print(\"\\nAll occurred errors:\")\n",
    "        for error in errors:\n",
    "            print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total patient directory count: 1000\n",
      "Target voxel spacing: (0.35, 0.35, 0.5)\n",
      "Target x,y size: 512\n",
      "Output directory: D:/imageCAS_preprocessed_f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data preprocessing:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data preprocessing:  22%|██▏       | 220/1000 [00:00<00:02, 299.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Interim Results (Processed directories: 200/1000) ===\n",
      "Processed: 0 files\n",
      "Skipped: 400 files\n",
      "Errors: 0 files\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data preprocessing:  42%|████▏     | 422/1000 [00:01<00:03, 188.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Interim Results (Processed directories: 400/1000) ===\n",
      "Processed: 0 files\n",
      "Skipped: 800 files\n",
      "Errors: 0 files\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data preprocessing:  62%|██████▏   | 623/1000 [00:02<00:01, 193.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Interim Results (Processed directories: 600/1000) ===\n",
      "Processed: 0 files\n",
      "Skipped: 1200 files\n",
      "Errors: 0 files\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data preprocessing:  83%|████████▎ | 831/1000 [00:03<00:00, 188.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Interim Results (Processed directories: 800/1000) ===\n",
      "Processed: 0 files\n",
      "Skipped: 1600 files\n",
      "Errors: 0 files\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data preprocessing: 100%|██████████| 1000/1000 [00:04<00:00, 213.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Interim Results (Processed directories: 1000/1000) ===\n",
      "Processed: 0 files\n",
      "Skipped: 2000 files\n",
      "Errors: 0 files\n",
      "==================================================\n",
      "\n",
      "=== Final Results ===\n",
      "Processed file count: 0\n",
      "Skipped file count: 2000\n",
      "Error count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "target_spacing = (0.35, 0.35, 0.5)\n",
    "target_xy_size = 512\n",
    "base_path = \"data/imageCAS\"\n",
    "output_base = \"D:/imageCAS_preprocessed\"\n",
    "\n",
    "preprocess_imageCAS(base_path, output_base, target_spacing, target_xy_size, check_interval=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing voxel size, image shape result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1900.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Voxel Size Statistics ===\n",
      "       voxel_x  voxel_y  voxel_z\n",
      "count  1000.00  1000.00   1000.0\n",
      "mean      0.35     0.35      0.5\n",
      "std       0.00     0.00      0.0\n",
      "min       0.35     0.35      0.5\n",
      "25%       0.35     0.35      0.5\n",
      "50%       0.35     0.35      0.5\n",
      "75%       0.35     0.35      0.5\n",
      "max       0.35     0.35      0.5\n",
      "\n",
      "=== Unique Voxel Size Combination ===\n",
      "   voxel_x  voxel_y  voxel_z  count\n",
      "0     0.35     0.35      0.5   1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = analyze_voxel_size_and_image_shape(base_path)\n",
    "\n",
    "print(\"\\n=== Voxel Size Statistics ===\")\n",
    "stats = df[['voxel_x', 'voxel_y', 'voxel_z']].describe()\n",
    "print(stats)\n",
    "\n",
    "# unique voxel size\n",
    "unique_voxels = df.groupby(['voxel_x', 'voxel_y', 'voxel_z']).size().reset_index(name='count')\n",
    "unique_voxels = unique_voxels.sort_values('count', ascending=False)\n",
    "print(\"\\n=== Unique Voxel Size Combination ===\")\n",
    "print(unique_voxels)\n",
    "\n",
    "df.to_csv('src/eda/voxel_size_comparison.csv', index=False)\n",
    "\n",
    "# check outliers (cases more than 2 standard deviations from the mean)\n",
    "if (unique_voxels.shape[0] > 1):\n",
    "    print(\"\\n=== Check Outliers ===\")\n",
    "    for col in ['voxel_x', 'voxel_y', 'voxel_z']:\n",
    "        mean = df[col].mean()\n",
    "        std = df[col].std()\n",
    "    outliers = df[abs(df[col] - mean) > 2*std]\n",
    "    if not outliers.empty:\n",
    "        print(f\"\\n{col} outliers:\")\n",
    "        print(outliers[['patient_id', col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1938.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Image Shape Statistics ===\n",
      "       shape_x  shape_y      shape_z\n",
      "count   1000.0   1000.0  1000.000000\n",
      "mean     512.0    512.0   257.496000\n",
      "std        0.0      0.0    25.678227\n",
      "min      512.0    512.0   166.000000\n",
      "25%      512.0    512.0   241.000000\n",
      "50%      512.0    512.0   275.000000\n",
      "75%      512.0    512.0   275.000000\n",
      "max      512.0    512.0   277.000000\n",
      "\n",
      "=== Unique Image Shape Combination ===\n",
      "    shape_x  shape_y  shape_z  count\n",
      "39      512      512      275    621\n",
      "3       512      512      206    126\n",
      "24      512      512      245     18\n",
      "22      512      512      241     15\n",
      "32      512      512      259     15\n",
      "10      512      512      223     13\n",
      "14      512      512      229     13\n",
      "20      512      512      239     12\n",
      "27      512      512      249     12\n",
      "23      512      512      243     12\n",
      "25      512      512      247     11\n",
      "33      512      512      261     11\n",
      "15      512      512      231     10\n",
      "29      512      512      253     10\n",
      "9       512      512      221     10\n",
      "16      512      512      233      9\n",
      "11      512      512      225      9\n",
      "12      512      512      227      8\n",
      "31      512      512      257      8\n",
      "19      512      512      237      7\n",
      "17      512      512      235      6\n",
      "34      512      512      263      6\n",
      "8       512      512      219      6\n",
      "30      512      512      255      6\n",
      "7       512      512      217      4\n",
      "28      512      512      251      4\n",
      "36      512      512      267      2\n",
      "26      512      512      248      2\n",
      "4       512      512      209      2\n",
      "35      512      512      265      1\n",
      "37      512      512      268      1\n",
      "38      512      512      269      1\n",
      "0       512      512      166      1\n",
      "21      512      512      240      1\n",
      "1       512      512      187      1\n",
      "18      512      512      236      1\n",
      "13      512      512      228      1\n",
      "6       512      512      215      1\n",
      "5       512      512      213      1\n",
      "2       512      512      200      1\n",
      "40      512      512      277      1\n",
      "\n",
      "=== Check Outliers ===\n",
      "\n",
      "shape_z outliers:\n",
      "     patient_id  shape_z\n",
      "4             5      206\n",
      "6             7      206\n",
      "14           15      206\n",
      "17           18      206\n",
      "28           29      206\n",
      "..          ...      ...\n",
      "981         982      206\n",
      "990         991      206\n",
      "995         996      206\n",
      "996         997      206\n",
      "998         999      206\n",
      "\n",
      "[129 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = analyze_voxel_size_and_image_shape(base_path)\n",
    "\n",
    "print(\"\\n=== Image Shape Statistics ===\")\n",
    "stats = df[['shape_x', 'shape_y', 'shape_z']].describe()\n",
    "print(stats)\n",
    "\n",
    "#unique image shape\n",
    "unique_shapes = df.groupby(['shape_x', 'shape_y', 'shape_z']).size().reset_index(name='count')\n",
    "unique_shapes = unique_shapes.sort_values('count', ascending=False)\n",
    "print(\"\\n=== Unique Image Shape Combination ===\")\n",
    "print(unique_shapes)\n",
    "\n",
    "df.to_csv('src/eda/image_shape_comparison.csv', index=False)\n",
    "\n",
    "# check outliers (cases more than 2 standard deviations from the mean)\n",
    "print(\"\\n=== Check Outliers ===\")\n",
    "for col in ['shape_x', 'shape_y', 'shape_z']:\n",
    "    mean = df[col].mean()\n",
    "    std = df[col].std()\n",
    "    outliers = df[abs(df[col] - mean) > 2*std]\n",
    "    if not outliers.empty:\n",
    "        print(f\"\\n{col} outliers:\")\n",
    "        print(outliers[['patient_id', col]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
